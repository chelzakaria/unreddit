{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import LlamaCPP\n",
    "from nltk.corpus import stopwords\n",
    "from cuml.cluster import HDBSCAN\n",
    "from cuml.manifold import UMAP\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom stop words list\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.extend(set(stopwords.words('french')))\n",
    "stop_words.extend(set(stopwords.words('arabic')))\n",
    "\n",
    "# add custom darija stop words\n",
    "stop_words.extend(['chi','li','mn','3la','ana','wach','wla','bghit','bach','ila','rah','m3a','nta','ghir','dial','الله','راه','شي','ديال','هاد','او','ماشي','باش','انا','اللي','حاجة','ليا','عندي'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          None\n",
       "1          None\n",
       "2          None\n",
       "3          None\n",
       "4          None\n",
       "           ... \n",
       "1203987    None\n",
       "1203988    None\n",
       "1203989    None\n",
       "1203990    None\n",
       "1203991    None\n",
       "Name: body, Length: 1203992, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load comments\n",
    "with open('../data/cleaned/comments.csv', 'r', encoding='utf-8') as file:\n",
    "    comments_df = pd.read_csv(file, low_memory=False)\n",
    "comments_df.fillna('', inplace=True)\n",
    "comments = []\n",
    "comments_df.body.apply(lambda x: comments.append(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "88897    None\n",
       "88898    None\n",
       "88899    None\n",
       "88900    None\n",
       "88901    None\n",
       "Name: body, Length: 88567, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load submissions\n",
    "with open('../data/cleaned/submissions.csv', 'r', encoding='utf-8') as file:\n",
    "    submissions = pd.read_csv(file)    \n",
    "submissions.fillna('', inplace=True)\n",
    "# drop rows where AutoModerator is the author\n",
    "submissions = submissions[submissions['author'] != 'AutoModerator']\n",
    "# concat title and selftext\n",
    "submissions['body'] = submissions['title'] + ' ' + submissions['selftext']\n",
    "posts = []\n",
    "submissions.body.apply(lambda x: posts.append(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>hide_score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83vri</td>\n",
       "      <td>taoufix</td>\n",
       "      <td></td>\n",
       "      <td>Facebook is lost case [pic]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2009-03-11 18:24:44</td>\n",
       "      <td>/r/Morocco/comments/83vri/facebook_is_lost_cas...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Facebook is lost case [pic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c6u7c</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rabat Agdal At Night</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2010-05-21 21:43:14</td>\n",
       "      <td>/r/Morocco/comments/c6u7c/rabat_agdal_at_night/</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Rabat Agdal At Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c7162</td>\n",
       "      <td>taoufix</td>\n",
       "      <td></td>\n",
       "      <td>Beach near Sidi Ifni at sunset [pic]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2010-05-22 15:53:13</td>\n",
       "      <td>/r/Morocco/comments/c7162/beach_near_sidi_ifni...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Beach near Sidi Ifni at sunset [pic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c71ir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Medina de Rabat on a hazy, lazy friday</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2010-05-22 16:43:48</td>\n",
       "      <td>/r/Morocco/comments/c71ir/medina_de_rabat_on_a...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Medina de Rabat on a hazy, lazy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c727d</td>\n",
       "      <td>taoufix</td>\n",
       "      <td></td>\n",
       "      <td>Tiznit traditional market street during lunch ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2010-05-22 18:11:18</td>\n",
       "      <td>/r/Morocco/comments/c727d/tiznit_traditional_m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tiznit traditional market street during lunch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88897</th>\n",
       "      <td>1d3ofx4</td>\n",
       "      <td>penelopelouiseb</td>\n",
       "      <td>:snoo_smile: Visitor</td>\n",
       "      <td>Beautiful Asilah!</td>\n",
       "      <td>Some of my photos from Asilah! It was on my Mo...</td>\n",
       "      <td>:art: Art &amp;amp; Photography</td>\n",
       "      <td>2024-05-29 22:22:27</td>\n",
       "      <td>/r/Morocco/comments/1d3ofx4/beautiful_asilah/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Beautiful Asilah! Some of my photos from Asila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88898</th>\n",
       "      <td>1d3ohin</td>\n",
       "      <td>Time-Ad-8776</td>\n",
       "      <td>:snoo_smile: Visitor</td>\n",
       "      <td>aliexpress fake airpods</td>\n",
       "      <td>can anyone recommend me chi fakes free shippin...</td>\n",
       "      <td>:technology: Science &amp;amp; Tech</td>\n",
       "      <td>2024-05-29 22:24:24</td>\n",
       "      <td>/r/Morocco/comments/1d3ohin/aliexpress_fake_ai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>aliexpress fake airpods can anyone recommend m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88899</th>\n",
       "      <td>1d3orn3</td>\n",
       "      <td>PotentialOrder5837</td>\n",
       "      <td>:snoo_smile: Visitor</td>\n",
       "      <td>Sending money to yourself for vacation</td>\n",
       "      <td>Hi \\nI plan to send myself around 50k dirhams ...</td>\n",
       "      <td>:travel: Travel</td>\n",
       "      <td>2024-05-29 22:37:01</td>\n",
       "      <td>/r/Morocco/comments/1d3orn3/sending_money_to_y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Sending money to yourself for vacation  Hi \\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88900</th>\n",
       "      <td>1d3pnbc</td>\n",
       "      <td>Leather_Alfalfa6519</td>\n",
       "      <td>:snoo_smile: Visitor</td>\n",
       "      <td>is it too late to leave? do I actually leave o...</td>\n",
       "      <td>I’m a 26 (turning 26 next month) y.o female wi...</td>\n",
       "      <td>:Discussion: Discussion</td>\n",
       "      <td>2024-05-29 23:17:22</td>\n",
       "      <td>/r/Morocco/comments/1d3pnbc/is_it_too_late_to_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>is it too late to leave? do I actually leave o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88901</th>\n",
       "      <td>1d3qfr9</td>\n",
       "      <td>Ab_Stark</td>\n",
       "      <td>:snoo_smile: Visitor</td>\n",
       "      <td>Relationship advice</td>\n",
       "      <td>Hi everyone, \\n\\n  \\nI have just had a rough a...</td>\n",
       "      <td>:Discussion: Discussion</td>\n",
       "      <td>2024-05-29 23:55:25</td>\n",
       "      <td>/r/Morocco/comments/1d3qfr9/relationship_advice/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Relationship advice Hi everyone, \\n\\n  \\nI hav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88567 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id               author     author_flair_text  \\\n",
       "0        83vri              taoufix                         \n",
       "1        c6u7c                                              \n",
       "2        c7162              taoufix                         \n",
       "3        c71ir                                              \n",
       "4        c727d              taoufix                         \n",
       "...        ...                  ...                   ...   \n",
       "88897  1d3ofx4      penelopelouiseb  :snoo_smile: Visitor   \n",
       "88898  1d3ohin         Time-Ad-8776  :snoo_smile: Visitor   \n",
       "88899  1d3orn3   PotentialOrder5837  :snoo_smile: Visitor   \n",
       "88900  1d3pnbc  Leather_Alfalfa6519  :snoo_smile: Visitor   \n",
       "88901  1d3qfr9             Ab_Stark  :snoo_smile: Visitor   \n",
       "\n",
       "                                                   title  \\\n",
       "0                            Facebook is lost case [pic]   \n",
       "1                                   Rabat Agdal At Night   \n",
       "2                   Beach near Sidi Ifni at sunset [pic]   \n",
       "3                 Medina de Rabat on a hazy, lazy friday   \n",
       "4      Tiznit traditional market street during lunch ...   \n",
       "...                                                  ...   \n",
       "88897                                  Beautiful Asilah!   \n",
       "88898                            aliexpress fake airpods   \n",
       "88899            Sending money to yourself for vacation    \n",
       "88900  is it too late to leave? do I actually leave o...   \n",
       "88901                                Relationship advice   \n",
       "\n",
       "                                                selftext  \\\n",
       "0                                                          \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "88897  Some of my photos from Asilah! It was on my Mo...   \n",
       "88898  can anyone recommend me chi fakes free shippin...   \n",
       "88899  Hi \\nI plan to send myself around 50k dirhams ...   \n",
       "88900  I’m a 26 (turning 26 next month) y.o female wi...   \n",
       "88901  Hi everyone, \\n\\n  \\nI have just had a rough a...   \n",
       "\n",
       "                       link_flair_text          created_utc  \\\n",
       "0                                       2009-03-11 18:24:44   \n",
       "1                                       2010-05-21 21:43:14   \n",
       "2                                       2010-05-22 15:53:13   \n",
       "3                                       2010-05-22 16:43:48   \n",
       "4                                       2010-05-22 18:11:18   \n",
       "...                                ...                  ...   \n",
       "88897      :art: Art &amp; Photography  2024-05-29 22:22:27   \n",
       "88898  :technology: Science &amp; Tech  2024-05-29 22:24:24   \n",
       "88899                  :travel: Travel  2024-05-29 22:37:01   \n",
       "88900          :Discussion: Discussion  2024-05-29 23:17:22   \n",
       "88901          :Discussion: Discussion  2024-05-29 23:55:25   \n",
       "\n",
       "                                               permalink  score  num_comments  \\\n",
       "0      /r/Morocco/comments/83vri/facebook_is_lost_cas...      3             3   \n",
       "1        /r/Morocco/comments/c6u7c/rabat_agdal_at_night/      3             2   \n",
       "2      /r/Morocco/comments/c7162/beach_near_sidi_ifni...      4             0   \n",
       "3      /r/Morocco/comments/c71ir/medina_de_rabat_on_a...      3             1   \n",
       "4      /r/Morocco/comments/c727d/tiznit_traditional_m...      3             1   \n",
       "...                                                  ...    ...           ...   \n",
       "88897      /r/Morocco/comments/1d3ofx4/beautiful_asilah/      1             1   \n",
       "88898  /r/Morocco/comments/1d3ohin/aliexpress_fake_ai...      1             1   \n",
       "88899  /r/Morocco/comments/1d3orn3/sending_money_to_y...      1             1   \n",
       "88900  /r/Morocco/comments/1d3pnbc/is_it_too_late_to_...      1             1   \n",
       "88901   /r/Morocco/comments/1d3qfr9/relationship_advice/      1             1   \n",
       "\n",
       "       over_18 hide_score                                               body  \n",
       "0        False      False                       Facebook is lost case [pic]   \n",
       "1        False      False                              Rabat Agdal At Night   \n",
       "2        False      False              Beach near Sidi Ifni at sunset [pic]   \n",
       "3        False      False            Medina de Rabat on a hazy, lazy friday   \n",
       "4        False      False  Tiznit traditional market street during lunch ...  \n",
       "...        ...        ...                                                ...  \n",
       "88897    False             Beautiful Asilah! Some of my photos from Asila...  \n",
       "88898    False             aliexpress fake airpods can anyone recommend m...  \n",
       "88899    False             Sending money to yourself for vacation  Hi \\nI...  \n",
       "88900    False             is it too late to leave? do I actually leave o...  \n",
       "88901    False             Relationship advice Hi everyone, \\n\\n  \\nI hav...  \n",
       "\n",
       "[88567 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer_model\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words, min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# define umap_model and hdbscan_model for GPU acceleration\n",
    "umap_model = UMAP(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "hdbscan_model = HDBSCAN(min_samples=10, gen_min_span_tree=True, prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label only in clean text no special characters or multiple labels.\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../models/zephyr-7b-alpha.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-alpha\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = huggingfaceh4_zephyr-7b-alpha\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    81.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'huggingfaceh4_zephyr-7b-alpha', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "representation_model = LlamaCPP(\"../models/zephyr-7b-alpha.Q4_K_M.gguf\", prompt=main_prompt)\n",
    "\n",
    "topic_model = BERTopic(representation_model=representation_model, verbose=True, language=\"multilingual\", vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 20:31:00,638 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd39514058d04a29bc2b152ba1b412db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 20:31:16,905 - BERTopic - Embedding - Completed ✓\n",
      "2024-06-06 20:31:16,906 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-06-06 20:31:17,388 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-06-06 20:31:17,396 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-06-06 20:31:19,236 - BERTopic - Cluster - Completed ✓\n",
      "2024-06-06 20:31:19,285 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested tokens (2275) exceed context window of 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/bertopic/_bertopic.py:433\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_representative_docs(custom_documents)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# Extract topics by calculating c-TF-IDF\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# Reduce topics\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics:\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/bertopic/_bertopic.py:3787\u001b[0m, in \u001b[0;36mBERTopic._extract_topics\u001b[0;34m(self, documents, embeddings, mappings, verbose)\u001b[0m\n\u001b[1;32m   3785\u001b[0m documents_per_topic \u001b[38;5;241m=\u001b[39m documents\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin})\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_tf_idf_, words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_tf_idf(documents_per_topic)\n\u001b[0;32m-> 3787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_representations_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_words_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_topic_vectors(documents\u001b[38;5;241m=\u001b[39mdocuments, embeddings\u001b[38;5;241m=\u001b[39membeddings, mappings\u001b[38;5;241m=\u001b[39mmappings)\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_labels_ \u001b[38;5;241m=\u001b[39m {key: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m values[:\u001b[38;5;241m4\u001b[39m]])\n\u001b[1;32m   3790\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   3791\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_representations_\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/bertopic/_bertopic.py:4071\u001b[0m, in \u001b[0;36mBERTopic._extract_words_per_topic\u001b[0;34m(self, words, documents, c_tf_idf, calculate_aspects)\u001b[0m\n\u001b[1;32m   4069\u001b[0m         topics \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mextract_topics(\u001b[38;5;28mself\u001b[39m, documents, c_tf_idf, topics)\n\u001b[1;32m   4070\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model, BaseRepresentation):\n\u001b[0;32m-> 4071\u001b[0m     topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_tf_idf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   4073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/bertopic/representation/_llamacpp.py:154\u001b[0m, in \u001b[0;36mLlamaCPP.extract_topics\u001b[0;34m(self, topic_model, documents, c_tf_idf, topics)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts_\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Extract result from generator and use that as label\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    155\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m [(description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m description \u001b[38;5;129;01min\u001b[39;00m topic_description]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(topic_description) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/llama_cpp/llama.py:1637\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1575\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \n\u001b[1;32m   1603\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/llama_cpp/llama.py:1570\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1570\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m~/folder/RedDash/env/lib/python3.11/site-packages/llama_cpp/llama.py:1048\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mreset_timings()\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt_tokens) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx:\n\u001b[0;32m-> 1048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested tokens (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompt_tokens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceed context window of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllama_cpp\u001b[38;5;241m.\u001b[39mllama_n_ctx(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1050\u001b[0m     )\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_tokens \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;66;03m# Unlimited, depending on n_ctx.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt_tokens)\n",
      "\u001b[0;31mValueError\u001b[0m: Requested tokens (2275) exceed context window of 512"
     ]
    }
   ],
   "source": [
    "topic_model.fit_transform(posts[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save('../models/llama_modelv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(posts)[topic_model.get_document_info(posts).Topic != -1].sort_values('Topic', ascending=False).head(10)[['Document','Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"../models/llama_model\", save_embedding_model=True, save_ctfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = [txt for txt in loaded_model.get_topic_info().head(25).Name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text in topics_list\n",
    "\n",
    "# remove digits at the beginning of the text\n",
    "\n",
    "import re\n",
    "\n",
    "# remove trailing underscores\n",
    "topics_list = [re.sub(r'_+$', '', txt) for txt in topics_list]\n",
    "# remove leading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
